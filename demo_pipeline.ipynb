{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Career Copilot ‚Äî –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è pipeline –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ —Å–∏—Å—Ç–µ–º–µ Career Copilot:  \n",
    "–æ—Ç –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤ –¥–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ —Ä–∞–∑–≤–∏—Ç–∏—è.\n",
    "\n",
    "**–°—Ç—Ä—É–∫—Ç—É—Ä–∞:**\n",
    "1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "2. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–≤—ã–∫–æ–≤ (pymorphy3 vs stemming)\n",
    "3. –ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—é–º–µ (PDF ‚Üí –Ω–∞–≤—ã–∫–∏ —á–µ—Ä–µ–∑ GPT)\n",
    "4. RAG pipeline (—ç–º–±–µ–¥–¥–∏–Ω–≥–∏ + Qdrant)\n",
    "5. –°—Ü–µ–Ω–∞—Ä–∏–∏ –∏ gap-–∞–Ω–∞–ª–∏–∑\n",
    "6. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–ª–∞–Ω–∞ —Ä–∞–∑–≤–∏—Ç–∏—è 70/20/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "–°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ç—Ä–µ–º—è JSON-—Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞–º–∏:  \n",
    "- **clean_skills.json** ‚Äî –Ω–∞–≤—ã–∫–∏ —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ –ø—Ä–æ—Ñ–µ—Å—Å–∏—è–º –∏ —É—Ä–æ–≤–Ω—è–º–∏ –≤–ª–∞–¥–µ–Ω–∏—è  \n",
    "- **atlas_params_clean.json** ‚Äî –º–µ—Ç–∞–∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞—Ç–ª–∞—Å–∞) –ø–æ –≥—Ä–µ–π–¥–∞–º  \n",
    "- **skill_synonyms.json** ‚Äî —Å–ª–æ–≤–∞—Ä—å —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–≤–æ–¥–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "PROJECT_DIR = Path(\".\").resolve()\n",
    "if str(PROJECT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_DIR))\n",
    "\n",
    "with open(\"data/clean_skills.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    skills_data = json.load(f)\n",
    "\n",
    "with open(\"data/atlas_params_clean.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    atlas_data = json.load(f)\n",
    "\n",
    "with open(\"data/skill_synonyms.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    synonyms_data = json.load(f)\n",
    "\n",
    "print(f\"–ù–∞–≤—ã–∫–æ–≤:          {len(skills_data)}\")\n",
    "print(f\"–ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∞—Ç–ª–∞—Å–∞: {len(atlas_data)}\")\n",
    "print(f\"–°–∏–Ω–æ–Ω–∏–º–æ–≤:         {len(synonyms_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞–ø–∏—Å–∏ –Ω–∞–≤—ã–∫–∞\n",
    "\n",
    "–ö–∞–∂–¥—ã–π –Ω–∞–≤—ã–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–ø–∏—Å–∞–Ω–∏—è —Ç—Ä—ë—Ö —É—Ä–æ–≤–Ω–µ–π –≤–ª–∞–¥–µ–Ω–∏—è (Basic / Proficiency / Advanced)  \n",
    "–∏ –ø—Ä–∏–º–µ—Ä—ã –∑–∞–¥–∞—á –Ω–∞ —Ä–∞–∑–≤–∏—Ç–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É—Ä–æ–≤–Ω—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_skill = skills_data[1]\n",
    "print(f\"–ù–∞–≤—ã–∫:      {example_skill.get('–ù–∞–≤—ã–∫')}\")\n",
    "print(f\"–ü—Ä–æ—Ñ–µ—Å—Å–∏—è:  {example_skill.get('–ü—Ä–æ—Ñ–µ—Å—Å–∏—è (–ª–∏—Å—Ç)')}\")\n",
    "print(f\"–ö–∞—Ç–µ–≥–æ—Ä–∏—è:  {example_skill.get('–ö–∞—Ç–µ–≥–æ—Ä–∏—è')}\")\n",
    "print(f\"–°–≤–æ–π—Å—Ç–≤–∞:   {example_skill.get('–°–≤–æ–π—Å—Ç–≤–∞')}\")\n",
    "print()\n",
    "print(\"--- –£—Ä–æ–≤–Ω–∏ –≤–ª–∞–¥–µ–Ω–∏—è ---\")\n",
    "for level in [\"Basic\", \"Proficiency\", \"Advanced\"]:\n",
    "    key = f\"Skill level \\\\\\\\ –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä - {level}\"\n",
    "    desc = example_skill.get(key, \"\")\n",
    "    print(f\"\\n{level}: {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. –ü—Ä–æ—Ñ–µ—Å—Å–∏–∏ –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_counts = Counter()\n",
    "category_counts = Counter()\n",
    "\n",
    "for s in skills_data:\n",
    "    prof = s.get(\"–ü—Ä–æ—Ñ–µ—Å—Å–∏—è (–ª–∏—Å—Ç)\") or s.get(\"–ü—Ä–∏–≤—è–∑–∫–∞ –∫ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏\", \"\")\n",
    "    cat = s.get(\"–ö–∞—Ç–µ–≥–æ—Ä–∏—è\", \"\")\n",
    "    if prof:\n",
    "        profession_counts[prof] += 1\n",
    "    if cat:\n",
    "        category_counts[cat] += 1\n",
    "\n",
    "print(f\"–ü—Ä–æ—Ñ–µ—Å—Å–∏–π: {len(profession_counts)}\")\n",
    "print(f\"–ö–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–∞–≤—ã–∫–æ–≤: {len(category_counts)}\")\n",
    "print()\n",
    "print(\"--- –ù–∞–≤—ã–∫–æ–≤ –ø–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏—è–º ---\")\n",
    "for prof, count in profession_counts.most_common():\n",
    "    short = prof.replace(\"–°–∫–∏–ª–ª—Å–µ—Ç \", \"\")\n",
    "    print(f\"  {short:45s} {count:3d} –Ω–∞–≤—ã–∫–æ–≤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- –¢–æ–ø-15 –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–∞–≤—ã–∫–æ–≤ ---\")\n",
    "for cat, count in category_counts.most_common(15):\n",
    "    print(f\"  {cat:45s} {count:3d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞—Ç–ª–∞—Å–∞ (–º–µ—Ç–∞–∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏)\n",
    "\n",
    "7 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –æ–±—â–∏—Ö –¥–ª—è –≤—Å–µ—Ö –ø—Ä–æ—Ñ–µ—Å—Å–∏–π.  \n",
    "–î–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ 5 –≥—Ä–µ–π–¥–∞–º: –ú–ª–∞–¥—à–∏–π ‚Üí –≠–∫—Å–ø–µ—Ä—Ç."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in atlas_data:\n",
    "    name = param.get(\"–ü–∞—Ä–∞–º–µ—Ç—Ä\", \"\")\n",
    "    desc = param.get(\"–û–ø–∏—Å–∞–Ω–∏–µ\", \"\")\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"–ü–∞—Ä–∞–º–µ—Ç—Ä: {name}\")\n",
    "    print(f\"–û–ø–∏—Å–∞–Ω–∏–µ: {desc[:120]}...\" if len(desc) > 120 else f\"–û–ø–∏—Å–∞–Ω–∏–µ: {desc}\")\n",
    "    print()\n",
    "    for grade in [\"–ú–ª–∞–¥—à–∏–π\", \"–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç\", \"–°—Ç–∞—Ä—à–∏–π\", \"–í–µ–¥—É—â–∏–π\", \"–≠–∫—Å–ø–µ—Ä—Ç\"]:\n",
    "        text = param.get(grade, \"\")\n",
    "        short = text[:100] + \"...\" if len(text) > 100 else text\n",
    "        print(f\"  {grade:12s} ‚îÇ {short}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. –°–ª–æ–≤–∞—Ä—å —Å–∏–Ω–æ–Ω–∏–º–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"–í—Å–µ–≥–æ —Å–∏–Ω–æ–Ω–∏–º–æ–≤: {len(synonyms_data)}\")\n",
    "print()\n",
    "print(\"--- –ü—Ä–∏–º–µ—Ä—ã –º–∞–ø–ø–∏–Ω–≥–∞ ---\")\n",
    "for synonym, canonical in synonyms_data.items():\n",
    "    print(f\"  '{synonym}' ‚Üí '{canonical}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. DataLoader ‚Äî —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º\n",
    "\n",
    "–ú–æ–¥—É–ª—å `data_loader.py` —Å—Ç—Ä–æ–∏—Ç –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞:  \n",
    "–º–∞–ø–ø–∏–Ω–≥ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–π ‚Üî –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã—Ö, –ø–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π —Ä–æ–ª–∏ –ø–æ –≥—Ä–µ–π–¥—É."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader\n",
    "\n",
    "data = DataLoader()\n",
    "\n",
    "all_roles = data.get_all_roles()\n",
    "print(f\"–î–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ ({len(all_roles)}):\")\n",
    "for role in all_roles:\n",
    "    print(f\"  ‚Ä¢ {role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"–ú–µ–Ω–µ–¥–∂–µ—Ä –ø—Ä–æ–¥—É–∫—Ç–∞\"\n",
    "role_skills = data.get_skills_for_role(role)\n",
    "print(f\"–ù–∞–≤—ã–∫–∏ –¥–ª—è '{role}' ({len(role_skills)}):\")\n",
    "for s in role_skills:\n",
    "    print(f\"  ‚Ä¢ {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_name = data.get_internal_role_name(role)\n",
    "requirements = data.get_role_requirements(internal_name, \"Middle\")\n",
    "\n",
    "atlas_params = [p.get(\"–ü–∞—Ä–∞–º–µ—Ç—Ä\") for p in atlas_data]\n",
    "skill_reqs = {k: v for k, v in requirements.items() if k not in atlas_params}\n",
    "param_reqs = {k: v for k, v in requirements.items() if k in atlas_params}\n",
    "\n",
    "print(f\"–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è '{role}' –Ω–∞ —É—Ä–æ–≤–Ω–µ Middle:\")\n",
    "print(f\"  –ù–∞–≤—ã–∫–æ–≤:    {len(skill_reqs)} (–≤—Å–µ –Ω–∞ —É—Ä–æ–≤–Ω–µ {list(skill_reqs.values())[0] if skill_reqs else '?'} ‚Äî Proficiency)\")\n",
    "print(f\"  –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {len(param_reqs)} (–≤—Å–µ –Ω–∞ —É—Ä–æ–≤–Ω–µ {list(param_reqs.values())[0] if param_reqs else '?'} ‚Äî –°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–≤—ã–∫–æ–≤\n",
    "\n",
    "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –≤–≤–µ—Å—Ç–∏ –Ω–∞–≤—ã–∫ –≤ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ.  \n",
    "–°–∏—Å—Ç–µ–º–∞ –ø—Ä–∏–≤–æ–¥–∏—Ç –≤–≤–æ–¥ –∫ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é —á–µ—Ä–µ–∑ —Ü–µ–ø–æ—á–∫—É:  \n",
    "**—Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ ‚Üí –æ–ø–µ—á–∞—Ç–∫–∏ ‚Üí –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è (pymorphy3) ‚Üí —Å–∏–Ω–æ–Ω–∏–º—ã**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è vs —Å—Ç–µ–º–º–∏–Ω–≥\n",
    "\n",
    "–°—Ç–µ–º–º–∏–Ω–≥ (NLTK Snowball) –≥—Ä—É–±–æ –æ—Ç—Å–µ–∫–∞–µ—Ç –æ–∫–æ–Ω—á–∞–Ω–∏—è, –∞ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è (pymorphy3)  \n",
    "–ø—Ä–∏–≤–æ–¥–∏—Ç —Å–ª–æ–≤–æ –∫ —Å–ª–æ–≤–∞—Ä–Ω–æ–π —Ñ–æ—Ä–º–µ —Å —É—á—ë—Ç–æ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy3\n",
    "\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "test_words = [\n",
    "    \"—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞\", \"—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫\", \"—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤\", \"—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏\",\n",
    "    \"—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\", \"—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫\", \"—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫–∏\",\n",
    "    \"—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ\", \"—É–ø—Ä–∞–≤–ª—è—Ç—å\", \"—É–ø—Ä–∞–≤–ª—è–µ—Ç\",\n",
    "    \"–∞–Ω–∞–ª–∏—Ç–∏–∫\", \"–∞–Ω–∞–ª–∏—Ç–∏–∫–∞\", \"–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π\",\n",
    "    \"–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è\", \"–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏\", \"–∫–æ–º–º—É–Ω–∏–∫–∞—Ç–∏–≤–Ω—ã–π\",\n",
    "]\n",
    "\n",
    "try:\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    stemmer = SnowballStemmer(\"russian\")\n",
    "    has_stemmer = True\n",
    "except Exception:\n",
    "    has_stemmer = False\n",
    "\n",
    "print(f\"{'–°–ª–æ–≤–æ':25s} ‚îÇ {'–õ–µ–º–º–∞ (pymorphy3)':25s}\", end=\"\")\n",
    "if has_stemmer:\n",
    "    print(f\" ‚îÇ {'–°—Ç–µ–º (Snowball)':25s}\", end=\"\")\n",
    "print(f\" ‚îÇ –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ?\")\n",
    "print(\"‚îÄ\" * 110)\n",
    "\n",
    "for word in test_words:\n",
    "    lemma = morph.parse(word)[0].normal_form\n",
    "    if has_stemmer:\n",
    "        stem = stemmer.stem(word)\n",
    "        match = \"‚úì\" if lemma == morph.parse(test_words[0])[0].normal_form else \" \"\n",
    "        print(f\"{word:25s} ‚îÇ {lemma:25s} ‚îÇ {stem:25s} ‚îÇ {match}\")\n",
    "    else:\n",
    "        print(f\"{word:25s} ‚îÇ {lemma:25s} ‚îÇ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è normalize_for_search\n",
    "\n",
    "–§—É–Ω–∫—Ü–∏—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: lowercase ‚Üí –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–ø–µ—á–∞—Ç–æ–∫ ‚Üí –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –ø–æ —Å–ª–æ–≤–∞–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skill_normalizer import normalize_for_search\n",
    "\n",
    "test_inputs = [\n",
    "    \"–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö\",\n",
    "    \"–∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö\",\n",
    "    \"–ú–ê–®–ò–ù–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï\",\n",
    "    \"–º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\",\n",
    "    \"–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞–º–∏\",\n",
    "    \"—É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–æ–º\",\n",
    "    \"–ø–∏—Ç–æ–Ω\",\n",
    "    \"Python\",\n",
    "    \"Data Science\",\n",
    "    \"–ù–∞–ø–∏—Å–∞–Ω–∏–µ –∫–æ–¥–∞\",\n",
    "]\n",
    "\n",
    "print(f\"{'–í–≤–æ–¥':35s} ‚îÇ {'–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞':35s}\")\n",
    "print(\"‚îÄ\" * 75)\n",
    "for inp in test_inputs:\n",
    "    norm = normalize_for_search(inp)\n",
    "    print(f\"{inp:35s} ‚îÇ {norm:35s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –≤ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (resolve_to_canonical)\n",
    "\n",
    "–¶–µ–ø–æ—á–∫–∞ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏: —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞ ‚Üí –ø–µ—Ä–µ–±–æ—Ä –∫–ª—é—á–µ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skill_normalizer import resolve_to_canonical, get_canonical_skills_set\n",
    "\n",
    "canonical_set = get_canonical_skills_set()\n",
    "print(f\"–ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏—Ö –Ω–∞–≤—ã–∫–æ–≤ –≤ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–µ: {len(canonical_set)}\")\n",
    "print()\n",
    "\n",
    "test_queries = [\n",
    "    \"–ø–∏—Ç–æ–Ω\",\n",
    "    \"–ü–∞–π—Ç–æ–Ω\",\n",
    "    \"python 3\",\n",
    "    \"—ç–∫—Å–µ–ª—å\",\n",
    "    \"–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\",\n",
    "    \"machine learning\",\n",
    "    \"—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞–º–∏\",\n",
    "    \"–∫–æ–º–∞–Ω–¥–Ω–∞—è —Ä–∞–±–æ—Ç–∞\",\n",
    "    \"–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ\",\n",
    "    \"–Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –Ω–∞–≤—ã–∫\",\n",
    "]\n",
    "\n",
    "print(f\"{'–í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è':30s} ‚îÇ {'–ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π –Ω–∞–≤—ã–∫':30s}\")\n",
    "print(\"‚îÄ\" * 65)\n",
    "for q in test_queries:\n",
    "    result = resolve_to_canonical(q, canonical_set)\n",
    "    print(f\"{q:30s} ‚îÇ {result or '‚Äî –Ω–µ –Ω–∞–π–¥–µ–Ω':30s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. –ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—é–º–µ\n",
    "\n",
    "–î–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å:\n",
    "1. **pypdf** ‚Äî –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF  \n",
    "2. **GPT-4o** ‚Äî –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ —Å –æ—Ü–µ–Ω–∫–æ–π —É—Ä–æ–≤–Ω—è (JSON mode)\n",
    "\n",
    "> –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–º–ø—Ç–∞ –∏ —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞.  \n",
    "> –†–µ–∞–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ —Ç—Ä–µ–±—É–µ—Ç OPENAI_API_KEY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resume_parser import ResumeParser\n",
    "from config import Config\n",
    "\n",
    "parser = ResumeParser()\n",
    "print(f\"OpenAI API –¥–æ—Å—Ç—É–ø–µ–Ω: {'–î–∞' if parser.client else '–ù–µ—Ç (OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω)'}\")\n",
    "print(f\"–ú–æ–¥–µ–ª—å: {Config.RESUME_PARSER_MODEL}\")\n",
    "print(f\"–õ–∏–º–∏—Ç —Ç–µ–∫—Å—Ç–∞: {Config.RESUME_TEXT_MAX_CHARS} —Å–∏–º–≤–æ–ª–æ–≤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_skills = list(data.skills_map.keys())[:20]\n",
    "skills_str = \", \".join(sample_skills)\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "–¢—ã HR-–∞–Ω–∞–ª–∏—Ç–∏–∫. –ò–∑–≤–ª–µ–∫–∏ –Ω–∞–≤—ã–∫–∏ –∏–∑ —Ä–µ–∑—é–º–µ, —Å–æ–ø–æ—Å—Ç–∞–≤—å —Å–æ —Å–ø–∏—Å–∫–æ–º: [{skills_str}, ...].\n",
    "–û—Ü–µ–Ω–∏ —É—Ä–æ–≤–µ–Ω—å 1-3 (1-Junior, 2-Middle, 3-Senior).\n",
    "–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ JSON: {{\"skills\": [{{\"name\": \"–Ω–∞–∑–≤–∞–Ω–∏–µ\", \"level\": —á–∏—Å–ª–æ}}]}}\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"--- –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è GPT-4o ---\")\n",
    "print(system_prompt)\n",
    "print()\n",
    "print(\"--- –ü—Ä–∏–º–µ—Ä –æ–∂–∏–¥–∞–µ–º–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ ---\")\n",
    "print(json.dumps({\n",
    "    \"skills\": [\n",
    "        {\"name\": \"SQL, YQL\", \"level\": 2},\n",
    "        {\"name\": \"–ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è\", \"level\": 3},\n",
    "        {\"name\": \"–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞–º–∏\", \"level\": 2},\n",
    "    ]\n",
    "}, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —É—Ä–æ–≤–Ω–µ–π\n",
    "\n",
    "GPT –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É—Ä–æ–≤–Ω–∏ 1-3.  \n",
    "–§—Ä–æ–Ω—Ç–µ–Ω–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —à–∫–∞–ª—É 0‚Äì2 (—à–∞–≥ 0.5).  \n",
    "–ú–∞–ø–ø–∏–Ω–≥: GPT 1‚Üí1, 2‚Üí1.5, 3‚Üí2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_mapping = {1: 1, 2: 1.5, 3: 2}\n",
    "\n",
    "gpt_response = [\n",
    "    {\"name\": \"SQL, YQL\", \"level\": 2},\n",
    "    {\"name\": \"–ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è\", \"level\": 3},\n",
    "    {\"name\": \"DataLens\", \"level\": 1},\n",
    "]\n",
    "\n",
    "level_labels = {0: '–ù–µ—Ç –Ω–∞–≤—ã–∫–∞', 0.5: '–ù–∞—á–∞–ª—å–Ω—ã–π', 1: '–ë–∞–∑–æ–≤—ã–π', 1.5: '–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π', 2: '–≠–∫—Å–ø–µ—Ä—Ç'}\n",
    "\n",
    "print(f\"{'–ù–∞–≤—ã–∫':25s} ‚îÇ {'GPT (1-3)':10s} ‚îÇ {'Frontend (0-2)':15s} ‚îÇ {'–£—Ä–æ–≤–µ–Ω—å'}\")\n",
    "print(\"‚îÄ\" * 75)\n",
    "\n",
    "for s in gpt_response:\n",
    "    fe_level = level_mapping.get(s[\"level\"], 1)\n",
    "    label = level_labels.get(fe_level, str(fe_level))\n",
    "    print(f\"{s['name']:25s} ‚îÇ {s['level']:10d} ‚îÇ {fe_level:15.1f} ‚îÇ {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. RAG Pipeline\n",
    "\n",
    "RAG (Retrieval-Augmented Generation) –æ–±–æ–≥–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç—ã —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º.\n",
    "\n",
    "**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**\n",
    "- **Sentence-Transformers** ‚Äî –º–æ–¥–µ–ª—å `paraphrase-multilingual-MiniLM-L12-v2` (384-dim)\n",
    "- **Qdrant** ‚Äî –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î —Å –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π –º–µ—Ç—Ä–∏–∫–æ–π\n",
    "\n",
    "> –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –ø–æ–∫–∞–∂–µ–º –ø—Ä–æ—Ü–µ—Å—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.  \n",
    "> –†–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –≤ Qdrant —Ç—Ä–µ–±—É–µ—Ç QDRANT_URL –∏ QDRANT_API_KEY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"–ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {Config.EMBED_MODEL_NAME}\")\n",
    "print(f\"Qdrant URL: {'–Ω–∞—Å—Ç—Ä–æ–µ–Ω' if Config.QDRANT_URL else '–Ω–µ –∑–∞–¥–∞–Ω'}\")\n",
    "print(f\"RAG –∫–æ–ª–ª–µ–∫—Ü–∏—è: {Config.RAG_COLLECTION_NAME}\")\n",
    "print(f\"Top-K: {Config.RAG_TOP_K}\")\n",
    "print(f\"Score threshold: {Config.RAG_SCORE_THRESHOLD}\")\n",
    "print(f\"Skill map threshold: {Config.SKILL_MAP_SIMILARITY_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å ~30 —Å–µ–∫)\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import numpy as np\n",
    "\n",
    "    model = SentenceTransformer(Config.EMBED_MODEL_NAME)\n",
    "\n",
    "    texts = [\n",
    "        \"–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞–º–∏ –≤ IT\",\n",
    "        \"Project management\",\n",
    "        \"–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\",\n",
    "        \"Machine learning\",\n",
    "        \"SQL-–∑–∞–ø—Ä–æ—Å—ã –∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\",\n",
    "        \"–ù–∞–ø–∏—Å–∞–Ω–∏–µ –∫–æ–¥–∞ –Ω–∞ Python\",\n",
    "    ]\n",
    "\n",
    "    embeddings = model.encode(texts)\n",
    "\n",
    "    print(f\"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {embeddings.shape[1]}\")\n",
    "    print(f\"–ö–æ–ª-–≤–æ —Ç–µ–∫—Å—Ç–æ–≤: {embeddings.shape[0]}\")\n",
    "    print()\n",
    "\n",
    "    # –ö–æ—Å–∏–Ω—É—Å–Ω–∞—è –±–ª–∏–∑–æ—Å—Ç—å –º–µ–∂–¥—É –ø–∞—Ä–∞–º–∏\n",
    "    from numpy.linalg import norm\n",
    "    def cosine_sim(a, b):\n",
    "        return np.dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "    print(\"--- –ö–æ—Å–∏–Ω—É—Å–Ω–∞—è –±–ª–∏–∑–æ—Å—Ç—å ---\")\n",
    "    pairs = [(0,1), (2,3), (0,2), (4,5), (0,4)]\n",
    "    for i, j in pairs:\n",
    "        sim = cosine_sim(embeddings[i], embeddings[j])\n",
    "        print(f\"  '{texts[i]}' ‚Üî '{texts[j]}'\")\n",
    "        print(f\"  ‚Üí similarity = {sim:.3f}\")\n",
    "        print()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"sentence-transformers –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Qdrant\n",
    "\n",
    "–ö–∞–∂–¥—ã–π –Ω–∞–≤—ã–∫ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç—Å—è –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç —Å payload:\n",
    "```json\n",
    "{\n",
    "  \"type\": \"skill\",\n",
    "  \"name\": \"SQL, YQL\",\n",
    "  \"profession\": \"ProductManager\",\n",
    "  \"text\": \"SQL, YQL ‚Äî –ü–∏—à–µ—Ç –ø—Ä–æ—Å—Ç—ã–µ SELECT-–∑–∞–ø—Ä–æ—Å—ã...\"\n",
    "}\n",
    "```\n",
    "\n",
    "–ü—Ä–∏ –ø–æ–∏—Å–∫–µ: –∑–∞–ø—Ä–æ—Å ‚Üí —ç–º–±–µ–¥–¥–∏–Ω–≥ ‚Üí cosine search –≤ Qdrant ‚Üí top-K —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. –°—Ü–µ–Ω–∞—Ä–∏–∏ –∏ gap-–∞–Ω–∞–ª–∏–∑\n",
    "\n",
    "–°–∏—Å—Ç–µ–º–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç—Ä–∏ —Å—Ü–µ–Ω–∞—Ä–∏—è. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è gap-–∞–Ω–∞–ª–∏–∑:  \n",
    "—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—É—â–∏—Ö –Ω–∞–≤—ã–∫–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ —Ü–µ–ª–µ–≤–æ–π —Ä–æ–ª–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. –ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "\n",
    "–ó–∞–¥–∞–¥–∏–º –ø—Ä–æ—Ñ–∏–ª—å: Product Manager, Middle, —Å –Ω–∞–±–æ—Ä–æ–º –Ω–∞–≤—ã–∫–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import GRADE_TO_PARAM_ORDINAL\n",
    "\n",
    "user_profile = {\n",
    "    \"profession\": \"–ú–µ–Ω–µ–¥–∂–µ—Ä –ø—Ä–æ–¥—É–∫—Ç–∞\",\n",
    "    \"grade\": \"Middle\",\n",
    "    \"skills\": {\n",
    "        \"SQL, YQL\": 2,\n",
    "        \"DataLens\": 1,\n",
    "        \"–¢—Ä–µ–∫–µ—Ä\": 2,\n",
    "        \"–ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è\": 2,\n",
    "        \"–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞–º–∏\": 1,\n",
    "        \"A/B-—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã\": 1,\n",
    "        \"–§–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á\": 2,\n",
    "    }\n",
    "}\n",
    "\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º –∞—Ç–ª–∞—Å-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ –≥—Ä–µ–π–¥—É)\n",
    "user_skills = dict(user_profile[\"skills\"])\n",
    "current_ordinal = GRADE_TO_PARAM_ORDINAL.get(user_profile[\"grade\"], 2)\n",
    "for param in atlas_data:\n",
    "    param_name = param.get(\"–ü–∞—Ä–∞–º–µ—Ç—Ä\")\n",
    "    if param_name not in user_skills:\n",
    "        user_skills[param_name] = current_ordinal\n",
    "\n",
    "print(f\"–ü—Ä–æ—Ñ–µ—Å—Å–∏—è: {user_profile['profession']}\")\n",
    "print(f\"–ì—Ä–µ–π–¥:     {user_profile['grade']}\")\n",
    "print(f\"–ù–∞–≤—ã–∫–æ–≤:   {len(user_profile['skills'])}\")\n",
    "print(f\"+ –∞—Ç–ª–∞—Å-–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {len(atlas_data)} (—É—Ä–æ–≤–µ–Ω—å {current_ordinal})\")\n",
    "print(f\"–ò—Ç–æ–≥–æ –∫–ª—é—á–µ–π: {len(user_skills)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. –°—Ü–µ–Ω–∞—Ä–∏–π ¬´–°–ª–µ–¥—É—é—â–∏–π –≥—Ä–µ–π–¥¬ª (Middle ‚Üí Senior)\n",
    "\n",
    "–ó–∞–≥—Ä—É–∂–∞–µ–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è Senior, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å —Ç–µ–∫—É—â–∏–º –ø—Ä–æ—Ñ–∏–ª–µ–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scenario_handler import ScenarioHandler\n",
    "from gap_analyzer import GapAnalyzer, level_display\n",
    "\n",
    "scenarios = ScenarioHandler(data)\n",
    "analyzer = GapAnalyzer()\n",
    "\n",
    "internal = data.get_internal_role_name(user_profile[\"profession\"])\n",
    "target_reqs, role_name = scenarios.next_grade(internal, user_profile[\"grade\"], user_skills)\n",
    "\n",
    "print(f\"–¶–µ–ª—å: {role_name}\")\n",
    "print(f\"–¢—Ä–µ–±–æ–≤–∞–Ω–∏–π –≤ —Ü–µ–ª–µ–≤–æ–º –≥—Ä–µ–π–¥–µ: {len(target_reqs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_param_names = [p.get(\"–ü–∞—Ä–∞–º–µ—Ç—Ä\") for p in atlas_data]\n",
    "atlas_map = {p.get(\"–ü–∞—Ä–∞–º–µ—Ç—Ä\"): p for p in atlas_data}\n",
    "\n",
    "structured = analyzer.analyze_structured(\n",
    "    user_skills, target_reqs, atlas_param_names, atlas_map\n",
    ")\n",
    "\n",
    "print(f\"–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {structured['match_percent']}%\")\n",
    "print(f\"–†–∞–∑—Ä—ã–≤–æ–≤ (–∞—Ç–ª–∞—Å):  {len(structured['atlas_gaps'])}\")\n",
    "print(f\"–†–∞–∑—Ä—ã–≤–æ–≤ (–Ω–∞–≤—ã–∫–∏): {len(structured['skill_gaps'])}\")\n",
    "print(f\"–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:   {len(structured['atlas_strong']) + len(structured['skill_strong'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- –†–∞–∑—Ä—ã–≤—ã –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –∞—Ç–ª–∞—Å–∞ ---\")\n",
    "print(f\"{'–ü–∞—Ä–∞–º–µ—Ç—Ä':35s} ‚îÇ {'–¢–µ–∫—É—â–∏–π':12s} ‚îÇ {'–¢—Ä–µ–±—É–µ–º—ã–π':12s} ‚îÇ {'Œî':3s} ‚îÇ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç\")\n",
    "print(\"‚îÄ\" * 85)\n",
    "for g in structured[\"atlas_gaps\"]:\n",
    "    curr_name = level_display(g[\"current\"], is_atlas=True)\n",
    "    req_name = level_display(g[\"required\"], is_atlas=True)\n",
    "    prio = \"üî¥ –ö—Ä–∏—Ç–∏—á.\" if g[\"priority\"] == 1 else \"üü° –£–º–µ—Ä–µ–Ω.\" if g[\"priority\"] == 2 else \"üü¢ –ù–µ–∑–Ω–∞—á.\"\n",
    "    print(f\"{g['name']:35s} ‚îÇ {curr_name:12s} ‚îÇ {req_name:12s} ‚îÇ {g['delta']:3d} ‚îÇ {prio}\")\n",
    "\n",
    "print(\"\\n--- –†–∞–∑—Ä—ã–≤—ã –ø–æ –Ω–∞–≤—ã–∫–∞–º ---\")\n",
    "print(f\"{'–ù–∞–≤—ã–∫':35s} ‚îÇ {'–¢–µ–∫—É—â–∏–π':12s} ‚îÇ {'–¢—Ä–µ–±—É–µ–º—ã–π':12s} ‚îÇ {'Œî':3s} ‚îÇ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç\")\n",
    "print(\"‚îÄ\" * 85)\n",
    "for g in structured[\"skill_gaps\"][:10]:\n",
    "    curr_name = level_display(g[\"current\"], is_atlas=False)\n",
    "    req_name = level_display(g[\"required\"], is_atlas=False)\n",
    "    prio = \"üî¥ –ö—Ä–∏—Ç–∏—á.\" if g[\"priority\"] == 1 else \"üü° –£–º–µ—Ä–µ–Ω.\" if g[\"priority\"] == 2 else \"üü¢ –ù–µ–∑–Ω–∞—á.\"\n",
    "    print(f\"{g['name']:35s} ‚îÇ {curr_name:12s} ‚îÇ {req_name:12s} ‚îÇ {g['delta']:3d} ‚îÇ {prio}\")\n",
    "\n",
    "if len(structured[\"skill_gaps\"]) > 10:\n",
    "    print(f\"... –∏ –µ—â—ë {len(structured['skill_gaps']) - 10} –Ω–∞–≤—ã–∫–æ–≤ —Å —Ä–∞–∑—Ä—ã–≤–∞–º–∏\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã ---\")\n",
    "for s in structured[\"skill_strong\"]:\n",
    "    lvl = level_display(s[\"level\"], is_atlas=False)\n",
    "    print(f\"  ‚úÖ {s['name']} ‚Äî {lvl}\")\n",
    "for s in structured[\"atlas_strong\"]:\n",
    "    lvl = level_display(s[\"level\"], is_atlas=True)\n",
    "    print(f\"  ‚úÖ {s['name']} ‚Äî {lvl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. –°—Ü–µ–Ω–∞—Ä–∏–π ¬´–°–º–µ–Ω–∞ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏¬ª\n",
    "\n",
    "–°—Ä–∞–≤–Ω–∏–º –Ω–∞–≤—ã–∫–∏ Product Manager —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ –ê–Ω–∞–ª–∏—Ç–∏–∫–∞-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_role = \"–ê–Ω–∞–ª–∏—Ç–∏–∫-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫\"\n",
    "target_internal = data.get_internal_role_name(target_role)\n",
    "target_reqs_switch = data.get_role_requirements(target_internal, \"Middle\")\n",
    "\n",
    "switch_result = analyzer.analyze_structured(\n",
    "    user_skills, target_reqs_switch, atlas_param_names, atlas_map\n",
    ")\n",
    "\n",
    "print(f\"–ü–µ—Ä–µ—Ö–æ–¥: {user_profile['profession']} ‚Üí {target_role}\")\n",
    "print(f\"–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {switch_result['match_percent']}%\")\n",
    "print(f\"–°–æ–≤–ø–∞–¥–∞—é—â–∏—Ö –Ω–∞–≤—ã–∫–æ–≤: {len(switch_result['skill_strong'])}\")\n",
    "print(f\"–ù–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –Ω–∞–≤—ã–∫–æ–≤: {len([g for g in switch_result['skill_gaps'] if g['current'] == 0])}\")\n",
    "print(f\"–ß–∞—Å—Ç–∏—á–Ω—ã—Ö (–Ω—É–∂–Ω–æ –ø—Ä–æ–∫–∞—á–∞—Ç—å): {len([g for g in switch_result['skill_gaps'] if g['current'] > 0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. –°—Ü–µ–Ω–∞—Ä–∏–π ¬´–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π¬ª\n",
    "\n",
    "–ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏, —Å—á–∏—Ç–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤,  \n",
    "–∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä—É–µ–º: –±–ª–∏–∂–∞–π—à–∏–µ (‚â•15%), —Å–º–µ–∂–Ω—ã–µ (5‚Äì15%), –¥–∞–ª—å–Ω–∏–µ (<5%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opps = scenarios.explore_opportunities(user_skills)\n",
    "\n",
    "print(f\"–ù–∞–π–¥–µ–Ω–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π: {len(opps)}\")\n",
    "print()\n",
    "print(f\"{'–†–æ–ª—å':45s} ‚îÇ {'–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ':12s} ‚îÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è\")\n",
    "print(\"‚îÄ\" * 80)\n",
    "for opp in sorted(opps, key=lambda x: -x.get(\"match\", 0))[:15]:\n",
    "    match = opp.get(\"match\", 0)\n",
    "    role_name_opp = opp.get(\"role\", \"\")\n",
    "    if match >= 15:\n",
    "        cat = \"üü¢ –ë–ª–∏–∂–∞–π—à–∞—è\"\n",
    "    elif match >= 5:\n",
    "        cat = \"üü° –°–º–µ–∂–Ω–∞—è\"\n",
    "    else:\n",
    "        cat = \"üî¥ –î–∞–ª—å–Ω—è—è\"\n",
    "    print(f\"{role_name_opp:45s} ‚îÇ {match:10.1f}% ‚îÇ {cat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–ª–∞–Ω–∞ —Ä–∞–∑–≤–∏—Ç–∏—è\n",
    "\n",
    "–§–∏–Ω–∞–ª—å–Ω—ã–π —ç—Ç–∞–ø: `output_formatter` —Å–æ–±–∏—Ä–∞–µ—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É –≤ Markdown,  \n",
    "–∑–∞—Ç–µ–º `plan_generator` –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –µ—ë –≤ GPT-4o –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–ª–∞–Ω–∞ 70/20/10.\n",
    "\n",
    "**–ú–æ–¥–µ–ª—å 70/20/10:**\n",
    "- **70%** ‚Äî –æ–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Ä–µ–∞–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏ –Ω–∞ —Ä–∞–±–æ—Ç–µ\n",
    "- **20%** ‚Äî –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ: –º–µ–Ω—Ç–æ—Ä—Å—Ç–≤–æ, –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å, code review\n",
    "- **10%** ‚Äî —Ñ–æ—Ä–º–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ: –∫—É—Ä—Å—ã, –∫–Ω–∏–≥–∏, —Ç—Ä–µ–Ω–∏–Ω–≥–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from output_formatter import OutputFormatter\n",
    "\n",
    "formatter = OutputFormatter(data)\n",
    "\n",
    "# –§–æ—Ä–º–∏—Ä—É–µ–º markdown-–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É (—à–∞–≥ 1)\n",
    "grade_sequence = [\"Junior\", \"Middle\", \"Senior\", \"Lead\", \"Expert\"]\n",
    "current_index = grade_sequence.index(user_profile[\"grade\"])\n",
    "target_grade = grade_sequence[min(current_index + 1, len(grade_sequence) - 1)]\n",
    "\n",
    "md = formatter.format_next_grade(\n",
    "    structured,\n",
    "    role_name,\n",
    "    user_profile[\"profession\"],\n",
    "    current_grade=user_profile[\"grade\"],\n",
    "    target_grade=target_grade,\n",
    "    profession_internal=internal,\n",
    ")\n",
    "\n",
    "# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 2000 —Å–∏–º–≤–æ–ª–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
    "preview = md[:2000]\n",
    "if len(md) > 2000:\n",
    "    preview += \"\\n\\n... [–æ–±—Ä–µ–∑–∞–Ω–æ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏] ...\"\n",
    "\n",
    "print(f\"–î–ª–∏–Ω–∞ –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞: {len(md)} —Å–∏–º–≤–æ–ª–æ–≤\")\n",
    "print(f\"{'='*70}\")\n",
    "print(preview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. –ü—Ä–æ–º–ø—Ç –¥–ª—è GPT-4o\n",
    "\n",
    "–ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–º–ø—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –≤ LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–ª–∞–Ω–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plan_generator import PlanGenerator, _compress_step1, MAX_STEP1_CHARS, MAX_TOKENS_RESPONSE\n",
    "\n",
    "compressed = _compress_step1(md)\n",
    "\n",
    "print(f\"–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: {len(md)} —Å–∏–º–≤–æ–ª–æ–≤\")\n",
    "print(f\"–°–∂–∞—Ç–∞—è –¥–ª—è LLM:           {len(compressed)} —Å–∏–º–≤–æ–ª–æ–≤ (–ª–∏–º–∏—Ç: {MAX_STEP1_CHARS})\")\n",
    "print(f\"Max tokens –æ—Ç–≤–µ—Ç–∞:        {MAX_TOKENS_RESPONSE}\")\n",
    "print(f\"–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞:              0.3\")\n",
    "print()\n",
    "\n",
    "prompt_template = f\"\"\"–¢—ã –∫–∞—Ä—å–µ—Ä–Ω—ã–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç. –ù–∞ –æ—Å–Ω–æ–≤–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Å–æ—Å—Ç–∞–≤—å –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω —Ä–∞–∑–≤–∏—Ç–∏—è.\n",
    "\n",
    "–¶–µ–ª—å: {role_name}\n",
    "–¢–∏–ø —Å—Ü–µ–Ω–∞—Ä–∏—è: –°–ª–µ–¥—É—é—â–∏–π –≥—Ä–µ–π–¥\n",
    "\n",
    "–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞:\n",
    "[—Å–∂–∞—Ç–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ ‚Äî {len(compressed)} —Å–∏–º–≤–æ–ª–æ–≤]\n",
    "\n",
    "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ç–≤–µ—Ç—É:\n",
    "1. –†–∞–∑–≤–∏—Ç–∏–µ —á–µ—Ä–µ–∑ —Ä–µ–∞–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏ (70%)\n",
    "2. –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –∏ –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å (20%)\n",
    "3. –ö—É—Ä—Å—ã –∏ —Ç—Ä–µ–Ω–∏–Ω–≥–∏ (10%)\n",
    "4. –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏ —á–µ–∫–ø–æ–∏–Ω—Ç—ã (4 / 8 / 12 –Ω–µ–¥–µ–ª—å)\"\"\"\n",
    "\n",
    "print(\"--- –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–º–ø—Ç–∞ ---\")\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–ª–∞–Ω–∞ (—Ç—Ä–µ–±—É–µ—Ç OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = PlanGenerator()\n",
    "\n",
    "if gen.client:\n",
    "    plan = gen.generate_plan_702010(\n",
    "        scenario_type=\"–°–ª–µ–¥—É—é—â–∏–π –≥—Ä–µ–π–¥\",\n",
    "        step1_markdown=md,\n",
    "        target_name=role_name,\n",
    "        context=f\"–¢–µ–∫—É—â–∏–π –≥—Ä–µ–π–¥: {user_profile['grade']}, —Ü–µ–ª–µ–≤–æ–π: {target_grade}\",\n",
    "    )\n",
    "    print(\"--- –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–ª–∞–Ω ---\")\n",
    "    print(plan[:3000])\n",
    "    if len(plan) > 3000:\n",
    "        print(f\"\\n... [–≤—Å–µ–≥–æ {len(plan)} —Å–∏–º–≤–æ–ª–æ–≤]\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ–º fallback-–ø–ª–∞–Ω:\")\n",
    "    print()\n",
    "    print(gen._fallback_plan(role_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. –ò—Ç–æ–≥–æ–≤—ã–π pipeline\n",
    "\n",
    "–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞, –∫–∞–∫ –µ–≥–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚ñ∏ –®–∞–≥ 1: –í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\")\n",
    "print(f\"  –ü—Ä–æ—Ñ–µ—Å—Å–∏—è: {user_profile['profession']}\")\n",
    "print(f\"  –ì—Ä–µ–π–¥: {user_profile['grade']}\")\n",
    "print(f\"  –ù–∞–≤—ã–∫–æ–≤: {len(user_profile['skills'])}\")\n",
    "print(f\"  –°—Ü–µ–Ω–∞—Ä–∏–π: –°–ª–µ–¥—É—é—â–∏–π –≥—Ä–µ–π–¥\")\n",
    "\n",
    "print(\"\\n‚ñ∏ –®–∞–≥ 2: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–≤—ã–∫–æ–≤\")\n",
    "from skill_normalizer import resolve_to_canonical, get_canonical_skills_set\n",
    "cs = get_canonical_skills_set()\n",
    "for name in user_profile[\"skills\"]:\n",
    "    canonical = resolve_to_canonical(name, cs)\n",
    "    if canonical and canonical != name:\n",
    "        print(f\"  '{name}' ‚Üí '{canonical}'\")\n",
    "    else:\n",
    "        print(f\"  '{name}' ‚Äî –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π\")\n",
    "\n",
    "print(f\"\\n‚ñ∏ –®–∞–≥ 3: –ó–∞–≥—Ä—É–∑–∫–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π ({role_name})\")\n",
    "print(f\"  –ù–∞–≤—ã–∫–æ–≤: {len(skill_reqs)}, –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {len(param_reqs)}\")\n",
    "\n",
    "print(f\"\\n‚ñ∏ –®–∞–≥ 4: Gap-–∞–Ω–∞–ª–∏–∑\")\n",
    "print(f\"  –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {structured['match_percent']}%\")\n",
    "print(f\"  –†–∞–∑—Ä—ã–≤–æ–≤: {len(structured['atlas_gaps'])} (–∞—Ç–ª–∞—Å) + {len(structured['skill_gaps'])} (–Ω–∞–≤—ã–∫–∏)\")\n",
    "\n",
    "print(f\"\\n‚ñ∏ –®–∞–≥ 5: –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏\")\n",
    "print(f\"  Markdown: {len(md)} —Å–∏–º–≤–æ–ª–æ–≤\")\n",
    "\n",
    "print(f\"\\n‚ñ∏ –®–∞–≥ 6: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–ª–∞–Ω–∞ 70/20/10\")\n",
    "if gen.client:\n",
    "    print(f\"  GPT-4o: –ø–ª–∞–Ω —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω ({len(plan)} —Å–∏–º–≤–æ–ª–æ–≤)\")\n",
    "else:\n",
    "    print(f\"  Fallback (OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω)\")\n",
    "\n",
    "print(f\"\\n‚ñ∏ –®–∞–≥ 7: –û—Ç–ø—Ä–∞–≤–∫–∞ –Ω–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥\")\n",
    "print(f\"  JSON: {{markdown: '...{len(md)} chars...', role_titles: null}}\")\n",
    "print(\"\\n‚úÖ Pipeline –∑–∞–≤–µ—Ä—à—ë–Ω\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}